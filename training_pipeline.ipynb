{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Set parameters that will control the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../_DATA/CarND/p3_behavioral_cloning/set_000/\"\n",
    "image_dir = \"IMG/\"\n",
    "driving_data_csv = \"driving_log_original.csv\"\n",
    "batch_size = 32 #256\n",
    "nb_epoch = 3 \n",
    "\n",
    "should_retrain_existing_model = False\n",
    "saved_model = \"model_epoch_33_val_acc_0.0.h5\"\n",
    "previous_trained_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Allocate only a fraction of memory to TensorFlow GPU process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cpu:0', '/gpu:0']\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aymericdamien/TensorFlow-Examples/issues/38#issuecomment-265599695\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9) # try range from 0.3 to 0.9\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))\n",
    "\n",
    "#### Show available CPU and GPU(s)\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_CPU_GPU():\n",
    "    devices = device_lib.list_local_devices()\n",
    "    #return [x.name for x in devices if x.device_type == 'CPU']\n",
    "    return [x.name for x in devices ]\n",
    "\n",
    "print(get_available_CPU_GPU())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fetch data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_path ../_DATA/CarND/p3_behavioral_cloning/set_000/driving_log_original.csv\n",
      "Number of imported CSV rows: 8037\n"
     ]
    }
   ],
   "source": [
    "from  DataHelper import read_csv\n",
    "csv_path = data_dir + driving_data_csv\n",
    "print(\"csv_path\", csv_path)\n",
    "headers, data = read_csv(data_dir + driving_data_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Split data into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent_validation 10\n",
      "training (6027, 7)\n",
      "testing (1206, 7)\n",
      "validation (803, 7)\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import split_random\n",
    "training, testing, validation = split_random(data, percent_train=75, percent_test=15) \n",
    "\n",
    "print(\"training\", training.shape)\n",
    "print(\"testing\", testing.shape)\n",
    "print(\"validation\", validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fetch and visualize training steering angles\n",
    "\n",
    "I would like to train a car on the set that has a nice bell curve distribution of values:\n",
    "- I can drive the car on the track backwards\n",
    "- I can flip each image (and value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_value -0.942695\n",
      "max_value 1.0\n",
      "spread 1.9427\n",
      "recommended number of classes 195\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAADgCAYAAAC6jeqSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmyRJ0pD4/7MgWZA5sxJhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f70a4efa5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from DataHelper import plot_histogram, get_steering_values, find_nearest\n",
    "steering_angles = get_steering_values(training)\n",
    "plot_histogram(\"steering values\", steering_angles, change_step=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extract image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image count 6027\n",
      "IMG/center_2016_12_01_13_46_36_569.jpg\n"
     ]
    }
   ],
   "source": [
    "from DataHelper import get_image_center_values \n",
    "image_names = get_image_center_values(training)\n",
    "print(\"image count\", image_names.shape[0])\n",
    "print(image_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create a list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_DATA/CarND/p3_behavioral_cloning/set_000/IMG/IMG/center_2016_12_01_13_46_36_569.jpg\n"
     ]
    }
   ],
   "source": [
    "image_paths = []\n",
    "for image_name in image_names: # [0:50]\n",
    "    image_paths.extend([data_dir + image_dir + image_name])\n",
    "print(image_paths[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read images and display a sample\n",
    "\n",
    "- make sure they are in the right color representation\n",
    "- use Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_paths[2] ../_DATA/CarND/p3_behavioral_cloning/set_000/IMG/IMG/center_2016_12_01_13_46_21_961.jpg\n",
      "training_features count 6027\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ca4489a58923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"sample_image  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from ImageHelper import read_image_array\n",
    "#training_features = [read_image_array(path) for path in image_paths]\n",
    "\n",
    "image_list = []\n",
    "for path in image_paths:\n",
    "    image_list.append(read_image_array(path))\n",
    "training_features = np.array(image_list) # numpy array, not just a list\n",
    "\n",
    "print (\"image_paths[2]\", image_paths[2] )\n",
    "print (\"training_features count\", len(training_features) )\n",
    "\n",
    "sample_image = training_features[2]\n",
    "print (\"sample_image  \", sample_image.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(sample_image) # cmap='gray' , cmap='rainbow'\n",
    "plt.show()\n",
    "\n",
    "#print(sample_image[0][0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import Keras (layer above TensorFlow)\n",
    "\n",
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ELU, InputLayer, Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "\n",
    "from keras.activations import relu, softmax\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "from DataHelper import mean_pred, false_rates\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, Convolution1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Build a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Minimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_CDNN_model_minimal(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Lambda(lambda x: x/255.0 - 0.5, # normalize RGB 0-255 to -0.5 to 0.5\n",
    "                     input_shape=input_shape,\n",
    "                    name=\"Normalize_RGB\"))\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', \n",
    "                            activation=\"relu\", dim_ordering='tf', name=\"Convo_ReLU_32x3x3_01\"))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same', \n",
    "                            activation=\"relu\", name=\"Convo_ReLU_32x5x5_02\" ))\n",
    "    model.add(Convolution2D(32, 5, 5, border_mode='same', \n",
    "                            activation=\"relu\", name=\"Convo_ReLU_32x5x5_03\" ))\n",
    "    model.add(Flatten())\n",
    "    #model.add(MaxPooling2D(pool_size=(2, 2), name=\"MaxPool_2x2\"))\n",
    "\n",
    "    model.add(Dense(256, activation=\"relu\", name=\"Dense_relu_256_01\")) #256\n",
    "    model.add(Dropout(0.25, name=\"Dropout_0.25_01\"))\n",
    "    model.add(Dense(256, activation=\"relu\", name=\"Dense_relu_256_02\" )) #256\n",
    "\n",
    "    # CLASSIFICATION\n",
    "    #model.add(Dense(41, activation='linear' , name=\"dense_3_41_linear\")) # default: linear | softmax | relu | sigmoid\n",
    "\n",
    "    # REGRESSION\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Define Generator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution1D, Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "def yield_generator(X_train, y_train):\n",
    "    while 1:\n",
    "        for i in range(1875):\n",
    "            if i % 50 == 0:\n",
    "                print (\"i = \" + str(i) )\n",
    "            yield X_train[i*32:(i+1)*32], y_train[i*32:(i+1)*32]\n",
    "            \n",
    "            \n",
    "def yield_generator_from_file(csv_file_path):\n",
    "    while 1:\n",
    "        f = open(csv_file_path)\n",
    "        for line in f:\n",
    "            # create numpy arrays of input data\n",
    "            # and labels, from each line in the file\n",
    "            x, y = process_line(line)\n",
    "            img = load_images(x)\n",
    "            yield (img, y)\n",
    "        f.close()\n",
    "\n",
    "model.fit_generator(\n",
    "    yield_generator_from_file('/my_file.txt'),\n",
    "    samples_per_epoch=10000, \n",
    "    nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Compile model (configure learning process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_shape = (160, 320, 3) # sample_image   (160, 320, 3)\n",
    "model = get_CDNN_model_minimal(input_shape)\n",
    "model.summary()\n",
    "# Before training a model, you need to configure the learning process, which is done via the compile method.\n",
    "# \n",
    "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "optimizer='sgd' # | 'rmsprop'\n",
    "loss_function=\"mse\" # | 'binary_crossentropy' | 'mse' | mean_squared_error | sparse_categorical_crossentropy\n",
    "metrics_array=['accuracy'] # , mean_pred, false_rates\n",
    "\n",
    "model.compile(optimizer, loss_function, metrics_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Replace model with one stored on disk\n",
    "\n",
    "- If you replace the model, the INPUT dimetions have to be the same as these trained\n",
    "- Name your models well"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if should_retrain_existing_model:\n",
    "    model_path = model_dir + model_to_continue_training\n",
    "    model = load_model(model_path) \n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train (fit) the model agaist given labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( \"training_features.shape\", len(training_features) )\n",
    "# REGRESSION\n",
    "history = model.fit(training_features, \n",
    "                    y = steering_angles, \n",
    "                    nb_epoch = nb_epoch, \n",
    "                    batch_size = batch_size, \n",
    "                    verbose = 2, \n",
    "                    validation_split = 0.2)\n",
    "\n",
    "# CLASSIFICATION\n",
    "#history = model.fit(training_features, \n",
    "#y_one_hot, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "conv2d_1_relu (Convolution2D)    (None, 160, 320, 32)  896         convolution2d_input_1[0][0]      \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1638400)       0           conv2d_1_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1)             1638401     flatten_1[0][0]                  \n",
    "====================================================================================================\n",
    "Total params: 1,639,297\n",
    "Trainable params: 1,639,297\n",
    "Non-trainable params: 0\n",
    "\n",
    "training_features.shape 590\n",
    "Train on 472 samples, validate on 118 samples\n",
    "- MacBook Pro CPU 13s / epoch\n",
    "- MacBook Pro GPU 5s / epoch\n",
    "\n",
    "\n",
    "\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "conv2d_1_relu (Convolution2D)    (None, 160, 320, 32)  896         convolution2d_input_1[0][0]      \n",
    "____________________________________________________________________________________________________\n",
    "conv2d_3_relu (Convolution2D)    (None, 160, 320, 32)  25632       conv2d_1_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1638400)       0           conv2d_3_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1)             1638401     flatten_1[0][0]                  \n",
    "====================================================================================================\n",
    "Total params: 1,664,929\n",
    "Trainable params: 1,664,929\n",
    "Non-trainable params: 0\n",
    "\n",
    "\n",
    "training_features.shape 590\n",
    "Train on 472 samples, validate on 118 samples\n",
    "- MacBook Pro CPU 114s / epoch\n",
    "- MacBook Pro GPU 29s / epoch (29%)\n",
    "\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "conv2d_1_relu (Convolution2D)    (None, 160, 320, 32)  896         convolution2d_input_1[0][0]      \n",
    "____________________________________________________________________________________________________\n",
    "conv2d_2_relu (Convolution2D)    (None, 160, 320, 32)  9248        conv2d_1_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "conv2d_3_relu (Convolution2D)    (None, 160, 320, 32)  25632       conv2d_2_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1638400)       0           conv2d_3_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1)             1638401     flatten_1[0][0]                  \n",
    "====================================================================================================\n",
    "Total params: 1,674,177\n",
    "Trainable params: 1,674,177\n",
    "Non-trainable params: 0\n",
    "\n",
    "Train on 472 samples, validate on 118 samples\n",
    "- MacBook Pro CPU 156s / epoch\n",
    "- MacBook Pro GPU ResourceExhaustedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "training_accuracy = str( history.history['acc'][nb_epoch-1])\n",
    "print(\"training_accuracy\", training_accuracy)\n",
    "\n",
    "training_error = str( history.history['loss'][nb_epoch-1])\n",
    "print(\"training_error\", training_error)\n",
    "\n",
    "validation_accuracy = str( history.history['val_acc'][nb_epoch-1])\n",
    "print(\"validation_accuracy\", validation_accuracy)\n",
    "\n",
    "validation_error = str( history.history['val_loss'][nb_epoch-1])\n",
    "print(\"validation_error\", validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creates a HDF5 file '___.h5'\n",
    "model.save(data_dir \n",
    "           + \"model_epoch_\" + str(nb_epoch + previous_trained_epochs) \n",
    "           + \"_val_acc_\" + str(validation_accuracy) \n",
    "           + \".h5\") \n",
    "#del model  # deletes the existing model\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# summarize history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy (bigger better)')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training accuracy', 'testing accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# summarize history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Validation error (smaller better)')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epochs run')\n",
    "plt.legend(['training error(loss)', 'validation error (loss)'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = data_dir + saved_model\n",
    "print(model_path)\n",
    "\n",
    "model = load_model(model_path) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_name = \"center_2016_12_01_13_38_59_461.jpg\" # stering 0.05219137\n",
    "original_steering_angle = 0.7315571\n",
    "\n",
    "image_path =  data_dir +   image_name\n",
    "print(image_path)\n",
    "image = read_image(image_path)\n",
    "print(image.shape)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict( image[None, :, :], \n",
    "                            batch_size = 1, \n",
    "                            verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extract top prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DataHelper import predict_class\n",
    "\n",
    "predicted_class = predict_class(predictions, steering_classes)\n",
    "\n",
    "print(\"original steering angle \\n\", original_steering_angle)\n",
    "print(\"top_prediction \\n\", predicted_class )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plot predictions (peaks are top classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(predictions[0])\n",
    "plt.title('predictions')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.legend(['predictions'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env py352_tf_gpu",
   "language": "python",
   "name": "py352_tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
