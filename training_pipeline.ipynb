{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Set parameters that will control the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"../_DATA/CarND/p3_behavioral_cloning/set_000/\"\n",
    "image_dir = \"IMG/\"\n",
    "driving_data_csv = \"driving_log.csv\"\n",
    "batch_size = 32 #256\n",
    "nb_epoch = 3 \n",
    "\n",
    "should_retrain_existing_model = False\n",
    "saved_model = \"model_epoch_33_val_acc_0.0.h5\"\n",
    "previous_trained_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Allocate only a fraction of memory to TensorFlow GPU process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/aymericdamien/TensorFlow-Examples/issues/38#issuecomment-265599695\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6) # try range from 0.333 ot .9\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True, gpu_options=gpu_options))\n",
    "\n",
    "#### Show available CPU and GPU(s)\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_CPU_GPU():\n",
    "    devices = device_lib.list_local_devices()\n",
    "    #return [x.name for x in devices if x.device_type == 'CPU']\n",
    "    return [x.name for x in devices ]\n",
    "\n",
    "print(get_available_CPU_GPU())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fetch data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from  DataHelper import read_csv\n",
    "csv_path = data_dir + driving_data_csv\n",
    "print(\"csv_path\", csv_path)\n",
    "headers, data = read_csv(data_dir + driving_data_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Split data into training, testing and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DataHelper import split_random\n",
    "training, testing, validation = split_random(data, percent_train=75, percent_test=15) \n",
    "\n",
    "print(\"training\", training.shape)\n",
    "print(\"testing\", testing.shape)\n",
    "print(\"validation\", validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fetch and visualize training steering angles\n",
    "\n",
    "I would like to train a car on the set that has a nice bell curve distribution of values:\n",
    "- I can drive the car on the track backwards\n",
    "- I can flip each image (and value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DataHelper import plot_histogram, get_steering_values, find_nearest\n",
    "steering_angles = get_steering_values(training)\n",
    "plot_histogram(\"steering values\", steering_angles, change_step=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extract image names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DataHelper import get_image_center_values \n",
    "image_names = get_image_center_values(training)\n",
    "print(\"image count\", image_names.shape[0])\n",
    "print(image_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create a list of image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "for image_name in image_names: # [0:50]\n",
    "    image_paths.extend([data_dir + image_dir + image_name])\n",
    "print(image_paths[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read images and display a sample\n",
    "\n",
    "- make sure they are in the right color representation\n",
    "- use Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from ImageHelper import read_image_array\n",
    "#training_features = [read_image_array(path) for path in image_paths]\n",
    "\n",
    "image_list = []\n",
    "for path in image_paths:\n",
    "    image_list.append(read_image_array(path))\n",
    "training_features = np.array(image_list) # numpy array, not just a list\n",
    "\n",
    "print (\"image_paths[2]\", image_paths[2] )\n",
    "print (\"training_features count\", len(training_features) )\n",
    "\n",
    "sample_image = training_features[2]\n",
    "print (\"sample_image  \", sample_image.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(sample_image) # cmap='gray' , cmap='rainbow'\n",
    "plt.show()\n",
    "\n",
    "#print(sample_image[0][0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import Keras (layer above TensorFlow)\n",
    "\n",
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import ELU, InputLayer, Input\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation, Lambda\n",
    "\n",
    "from keras.activations import relu, softmax\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "from DataHelper import mean_pred, false_rates\n",
    "\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, Convolution1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Expected to see 1 arrays but instead got the following list of 8792 arrays: [array([[[203, 156, 129],\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# sample_image   (160, 320, 3)\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', activation=\"relu\" ,\n",
    "                        input_shape=(160, 320 ,3), dim_ordering='tf', name=\"conv2d_1_relu\"))\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='same', activation=\"relu\", name=\"conv2d_2_relu\" ))\n",
    "model.add(Convolution2D(32, 5, 5, border_mode='same', activation=\"relu\", name=\"conv2d_3_relu\" ))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Dense(256, activation=\"relu\", name=\"dense_1_relu\")) #256\n",
    "#model.add(Dropout(0.25, name=\"dropout_1_0.25\"))\n",
    "#model.add(Dense(256, activation=\"relu\", name=\"dense_2_relu\" )) #256\n",
    "\n",
    "# CLASSIFICATION\n",
    "#model.add(Dense(41, activation='linear' , name=\"dense_3_41_linear\")) # default: linear | softmax | relu | sigmoid\n",
    "\n",
    "# REGRESSION\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Compile model (configure learning process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Before training a model, you need to configure the learning process, which is done via the compile method.\n",
    "# \n",
    "# keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "optimizer='sgd' # | 'rmsprop'\n",
    "loss_function=\"mse\" # | 'binary_crossentropy' | 'mse' | mean_squared_error | sparse_categorical_crossentropy\n",
    "metrics_array=['accuracy'] # , mean_pred, false_rates\n",
    "\n",
    "model.compile(optimizer, loss_function, metrics_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Replace model with one stored on disk\n",
    "\n",
    "- If you replace the model, the INPUT dimetions have to be the same as these trained\n",
    "- Name your models well"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if should_retrain_existing_model:\n",
    "    model_path = model_dir + model_to_continue_training\n",
    "    model = load_model(model_path) \n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train (fit) the model agaist given labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( \"training_features.shape\", len(training_features) )\n",
    "# REGRESSION\n",
    "history = model.fit(training_features, \n",
    "                    y = steering_angles, \n",
    "                    nb_epoch = nb_epoch, \n",
    "                    batch_size = batch_size, \n",
    "                    verbose = 2, \n",
    "                    validation_split = 0.2)\n",
    "\n",
    "# CLASSIFICATION\n",
    "#history = model.fit(training_features, \n",
    "#y_one_hot, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "conv2d_1_relu (Convolution2D)    (None, 160, 320, 32)  896         convolution2d_input_1[0][0]      \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1638400)       0           conv2d_1_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1)             1638401     flatten_1[0][0]                  \n",
    "====================================================================================================\n",
    "Total params: 1,639,297\n",
    "Trainable params: 1,639,297\n",
    "Non-trainable params: 0\n",
    "\n",
    "training_features.shape 590\n",
    "Train on 472 samples, validate on 118 samples\n",
    "- MacBook Pro CPU 13s / epoch\n",
    "- MacBook Pro GPU 5s / epoch\n",
    "\n",
    "\n",
    "\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "conv2d_1_relu (Convolution2D)    (None, 160, 320, 32)  896         convolution2d_input_1[0][0]      \n",
    "____________________________________________________________________________________________________\n",
    "conv2d_3_relu (Convolution2D)    (None, 160, 320, 32)  25632       conv2d_1_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1638400)       0           conv2d_3_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1)             1638401     flatten_1[0][0]                  \n",
    "====================================================================================================\n",
    "Total params: 1,664,929\n",
    "Trainable params: 1,664,929\n",
    "Non-trainable params: 0\n",
    "\n",
    "\n",
    "training_features.shape 590\n",
    "Train on 472 samples, validate on 118 samples\n",
    "- MacBook Pro CPU 114s / epoch\n",
    "- MacBook Pro GPU 29s / epoch (29%)\n",
    "\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "conv2d_1_relu (Convolution2D)    (None, 160, 320, 32)  896         convolution2d_input_1[0][0]      \n",
    "____________________________________________________________________________________________________\n",
    "conv2d_2_relu (Convolution2D)    (None, 160, 320, 32)  9248        conv2d_1_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "conv2d_3_relu (Convolution2D)    (None, 160, 320, 32)  25632       conv2d_2_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 1638400)       0           conv2d_3_relu[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1)             1638401     flatten_1[0][0]                  \n",
    "====================================================================================================\n",
    "Total params: 1,674,177\n",
    "Trainable params: 1,674,177\n",
    "Non-trainable params: 0\n",
    "\n",
    "Train on 472 samples, validate on 118 samples\n",
    "- MacBook Pro CPU 156s / epoch\n",
    "- MacBook Pro GPU ResourceExhaustedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "training_accuracy = str( history.history['acc'][nb_epoch-1])\n",
    "print(\"training_accuracy\", training_accuracy)\n",
    "\n",
    "training_error = str( history.history['loss'][nb_epoch-1])\n",
    "print(\"training_error\", training_error)\n",
    "\n",
    "validation_accuracy = str( history.history['val_acc'][nb_epoch-1])\n",
    "print(\"validation_accuracy\", validation_accuracy)\n",
    "\n",
    "validation_error = str( history.history['val_loss'][nb_epoch-1])\n",
    "print(\"validation_error\", validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# creates a HDF5 file '___.h5'\n",
    "model.save(data_dir \n",
    "           + \"model_epoch_\" + str(nb_epoch + previous_trained_epochs) \n",
    "           + \"_val_acc_\" + str(validation_accuracy) \n",
    "           + \".h5\") \n",
    "#del model  # deletes the existing model\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# summarize history for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy (bigger better)')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training accuracy', 'testing accuracy'], loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# summarize history for loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Validation error (smaller better)')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epochs run')\n",
    "plt.legend(['training error(loss)', 'validation error (loss)'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_path = data_dir + saved_model\n",
    "print(model_path)\n",
    "\n",
    "model = load_model(model_path) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_name = \"center_2016_12_01_13_38_59_461.jpg\" # stering 0.05219137\n",
    "original_steering_angle = 0.7315571\n",
    "\n",
    "image_path =  data_dir +   image_name\n",
    "print(image_path)\n",
    "image = read_image(image_path)\n",
    "print(image.shape)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict( image[None, :, :], \n",
    "                            batch_size = 1, \n",
    "                            verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Extract top prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DataHelper import predict_class\n",
    "\n",
    "predicted_class = predict_class(predictions, steering_classes)\n",
    "\n",
    "print(\"original steering angle \\n\", original_steering_angle)\n",
    "print(\"top_prediction \\n\", predicted_class )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Plot predictions (peaks are top classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(predictions[0])\n",
    "plt.title('predictions')\n",
    "plt.ylabel('y')\n",
    "plt.xlabel('x')\n",
    "plt.legend(['predictions'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda env py352_tf_gpu",
   "language": "python",
   "name": "py352_tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
